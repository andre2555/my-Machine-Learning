{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-28T02:53:55.702787Z",
     "start_time": "2018-03-28T02:53:51.525445Z"
    }
   },
   "source": [
    "**Abstract**: this is a classical sentiment analysis problem. The input is a variable length text and the output is one of the 12 classes. One naive solution is to use the TFIDF model. This model relies on the statistics of the characters in each text to make the prediction. The drawback of this model is that it cannot capture the dependency between consecutive characters, hence loses valuable information there.\n",
    "\n",
    "RNN is better suited for this problem as it respects the order of the characters in a sequence. So we are going to try 2 different RNN models for this problem. The 1st RNN model is a standard LSTM architecture, which can be found in the Keras sample applications (https://github.com/keras-team/keras/blob/master/examples/imdb_lstm.py). It simply contains an LSTM model and a Dense layer.\n",
    "\n",
    "*Model 1: LSTM => Dense* (accuracy result: 25.1%)\n",
    "\n",
    "The 2nd model that we are going to try is much more complicated than the 1st model. It uses a stack of CNN layers to process the text before feeding to a Bidirectional LSTM. This architecture was found to perform the best among the alternatives in https://arxiv.org/pdf/1602.02410.pdf. The CNN layers are to discover the words with strong sentiment that may be more relevant to the label of the whole text.\n",
    "\n",
    "*Model 2: CNN => CNN => CNN => Bidirectional LSTM => Dense => Dense* (accuracy result: 84.7%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make the train set and the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-29T02:24:16.092804Z",
     "start_time": "2018-03-29T02:24:14.922299Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andy/anaconda2/envs/tf/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers import Dense, Embedding, LSTM, Conv1D, Dropout, MaxPooling1D, Bidirectional\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-29T02:24:16.148271Z",
     "start_time": "2018-03-29T02:24:16.095168Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read the text and the labels from files\n",
    "x_train = []\n",
    "\n",
    "for line in open('xtrain_obfuscated.txt'):\n",
    "    x_train += [line.strip()]\n",
    "    \n",
    "y_train = []\n",
    "for line in open('ytrain.txt'):\n",
    "    y_train += [int(line)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess input text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-29T02:24:20.513389Z",
     "start_time": "2018-03-29T02:24:16.156233Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all characters: ['a', 'c', 'b', 'e', 'd', 'g', 'f', 'i', 'h', 'k', 'j', 'm', 'l', 'o', 'n', 'q', 'p', 's', 'r', 'u', 't', 'w', 'v', 'y', 'x', 'z'] \n",
      "\n",
      "number of characters: 26 \n",
      "\n",
      "histogram of line lengths (max 452)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nx/4f8bh1pqEHzWEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc7e88d2ad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# find out all characters in the text\n",
    "all_chars = set()\n",
    "all_lens = []\n",
    "\n",
    "for line in x_train:\n",
    "    for char in line:\n",
    "        all_chars.add(char)\n",
    "    all_lens += [len(line)]\n",
    "    \n",
    "# make the dictionary to map character to index\n",
    "all_chars = list(all_chars)\n",
    "all_chars = {all_chars[i]:(i+1) for i in range(len(all_chars))}\n",
    "\n",
    "# plus 1 to account for the padding\n",
    "max_features = len(all_chars) + 1\n",
    "\n",
    "# max length of lines\n",
    "max_len = max(all_lens)\n",
    "\n",
    "# convert characters to indices using all_chars dictionary\n",
    "for i, line in enumerate(x_train):\n",
    "    x_train[i] = [all_chars[char] for char in line]\n",
    "    \n",
    "# pad shorter lines to max_len\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=max_len)\n",
    "        \n",
    "print 'all characters:', all_chars.keys(), '\\n'\n",
    "print 'number of characters:', len(all_chars), '\\n'\n",
    "print 'histogram of line lengths (max ' + str(max_len) + ')'\n",
    "_ = plt.hist(all_lens, bins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-29T02:24:20.540002Z",
     "start_time": "2018-03-29T02:24:20.523077Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all labels: set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]) \n",
      "\n",
      "number of labels: 12\n"
     ]
    }
   ],
   "source": [
    "# find out all the labels in the labels\n",
    "all_labels = set()\n",
    "\n",
    "for label in y_train:\n",
    "    all_labels.add(label)\n",
    "    \n",
    "nb_labels = len(all_labels)\n",
    "\n",
    "# convert y_train to one-hot encoding\n",
    "indices = np.array(y_train)\n",
    "y_train = np.zeros((len(indices), nb_labels))\n",
    "y_train[np.arange(len(indices)), indices] = 1\n",
    "        \n",
    "print 'all labels:', all_labels, '\\n'\n",
    "print 'number of labels:', nb_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-29T02:24:20.605898Z",
     "start_time": "2018-03-29T02:24:20.541842Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (27636, 452)\n",
      "y_train shape: (27636, 12)\n",
      "x_valid shape: (4877, 452)\n",
      "y_valid shape: (4877, 12)\n"
     ]
    }
   ],
   "source": [
    "# split the data into the train set and the validation set\n",
    "np.random.seed(0)\n",
    "nb_exam = len(x_train)\n",
    "indices = np.random.permutation(nb_exam)\n",
    "\n",
    "x_valid = x_train[indices[int(nb_exam*0.85):]]\n",
    "y_valid = y_train[indices[int(nb_exam*0.85):]]\n",
    "\n",
    "x_train = x_train[indices[:int(nb_exam*0.85)]]\n",
    "y_train = y_train[indices[:int(nb_exam*0.85)]]\n",
    "np.random.seed()\n",
    "\n",
    "print 'x_train shape:', x_train.shape\n",
    "print 'y_train shape:', y_train.shape\n",
    "\n",
    "print 'x_valid shape:', x_valid.shape\n",
    "print 'y_valid shape:', y_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make and train 2 RNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: vanila model for sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-28T10:21:33.161934Z",
     "start_time": "2018-03-28T10:21:32.646458Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(12, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-28T10:36:07.073195Z",
     "start_time": "2018-03-28T10:28:00.582170Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27636 samples, validate on 4877 samples\n",
      "Epoch 1/100\n",
      "27636/27636 [==============================] - 97s 4ms/step - loss: 2.2102 - acc: 0.2105 - val_loss: 2.2150 - val_acc: 0.2253\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.22534, saving model to model_1.h5\n",
      "Epoch 2/100\n",
      "27636/27636 [==============================] - 98s 4ms/step - loss: 2.2095 - acc: 0.2086 - val_loss: 2.1329 - val_acc: 0.2506\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.22534 to 0.25056, saving model to model_1.h5\n",
      "Epoch 3/100\n",
      "27636/27636 [==============================] - 98s 4ms/step - loss: 2.1938 - acc: 0.2132 - val_loss: 2.1902 - val_acc: 0.2094\n",
      "\n",
      "Epoch 00003: val_acc did not improve\n",
      "Epoch 4/100\n",
      "27636/27636 [==============================] - 97s 4ms/step - loss: 2.1915 - acc: 0.2131 - val_loss: 2.1793 - val_acc: 0.2130\n",
      "\n",
      "Epoch 00004: val_acc did not improve\n",
      "Epoch 5/100\n",
      "27636/27636 [==============================] - 97s 4ms/step - loss: 2.1808 - acc: 0.2167 - val_loss: 2.1408 - val_acc: 0.2321\n",
      "\n",
      "Epoch 00005: val_acc did not improve\n",
      "Epoch 00005: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6588666d10>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 256\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_acc', \n",
    "                           min_delta=0.001, \n",
    "                           patience=3, \n",
    "                           mode='max', \n",
    "                           verbose=1)\n",
    "\n",
    "checkpoint = ModelCheckpoint('model_1.h5', \n",
    "                             monitor='val_acc', \n",
    "                             verbose=1, \n",
    "                             save_best_only=True, \n",
    "                             mode='max', \n",
    "                             period=1)\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=100,\n",
    "          callbacks=[early_stop, checkpoint],\n",
    "          validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-28T10:36:55.968253Z",
     "start_time": "2018-03-28T10:36:51.465159Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4877/4877 [==============================] - 4s 903us/step\n",
      "('Validation score:', 2.1329242040173844)\n",
      "('Validation accuracy:', 0.2505638712628689)\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('model_1.h5')\n",
    "score, acc = model.evaluate(x_valid, \n",
    "                            y_valid,\n",
    "                            batch_size=batch_size)\n",
    "\n",
    "print('Validation score:', score)\n",
    "print('Validation accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: CNN and Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-29T03:12:59.539663Z",
     "start_time": "2018-03-29T03:12:58.784420Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filter_length = [5, 3, 3]\n",
    "nb_filter = [196, 196, 256]\n",
    "pool_length = 2\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(max_features, 128))\n",
    "\n",
    "for i in range(len(nb_filter)):\n",
    "    model.add(Conv1D(filters=nb_filter[i],\n",
    "                     kernel_size=filter_length[i],\n",
    "                     padding='valid',\n",
    "                     activation='relu',\n",
    "                     kernel_initializer='glorot_normal',\n",
    "                     strides=1))\n",
    "    model.add(Dropout(0.15))\n",
    "    model.add(MaxPooling1D(pool_size=pool_length))\n",
    "\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=False, dropout=0.15, recurrent_dropout=0.15)))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(12, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-29T03:23:45.617347Z",
     "start_time": "2018-03-29T03:20:05.561617Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27636 samples, validate on 4877 samples\n",
      "Epoch 1/100\n",
      "27636/27636 [==============================] - 44s 2ms/step - loss: 0.2764 - acc: 0.9101 - val_loss: 0.5881 - val_acc: 0.8343\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.83432, saving model to model_2.h5\n",
      "Epoch 2/100\n",
      "27636/27636 [==============================] - 44s 2ms/step - loss: 0.2825 - acc: 0.9056 - val_loss: 0.5507 - val_acc: 0.8474\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.83432 to 0.84745, saving model to model_2.h5\n",
      "Epoch 3/100\n",
      "27636/27636 [==============================] - 44s 2ms/step - loss: 0.2793 - acc: 0.9079 - val_loss: 0.5660 - val_acc: 0.8378\n",
      "\n",
      "Epoch 00003: val_acc did not improve\n",
      "Epoch 4/100\n",
      "27636/27636 [==============================] - 44s 2ms/step - loss: 0.2726 - acc: 0.9127 - val_loss: 0.5528 - val_acc: 0.8442\n",
      "\n",
      "Epoch 00004: val_acc did not improve\n",
      "Epoch 5/100\n",
      "27636/27636 [==============================] - 44s 2ms/step - loss: 0.2654 - acc: 0.9151 - val_loss: 0.5523 - val_acc: 0.8466\n",
      "\n",
      "Epoch 00005: val_acc did not improve\n",
      "Epoch 00005: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc799cde150>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 256\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_acc', \n",
    "                           min_delta=0.001, \n",
    "                           patience=3, \n",
    "                           mode='max', \n",
    "                           verbose=1)\n",
    "\n",
    "checkpoint = ModelCheckpoint('model_2.h5', \n",
    "                             monitor='val_acc', \n",
    "                             verbose=1, \n",
    "                             save_best_only=True, \n",
    "                             mode='max', \n",
    "                             period=1)\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=100,\n",
    "          callbacks=[early_stop, checkpoint],\n",
    "          validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-29T03:25:59.142475Z",
     "start_time": "2018-03-29T03:25:56.967947Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4877/4877 [==============================] - 2s 441us/step\n",
      "('Validation score:', 0.550671717543472)\n",
      "('Validation accuracy:', 0.8474472011482469)\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('model_2.h5')\n",
    "score, acc = model.evaluate(x_valid, \n",
    "                            y_valid,\n",
    "                            batch_size=batch_size)\n",
    "\n",
    "print('Validation score:', score)\n",
    "print('Validation accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-29T03:34:37.483865Z",
     "start_time": "2018-03-29T03:34:31.515594Z"
    }
   },
   "outputs": [],
   "source": [
    "# read the text from file\n",
    "x_test = []\n",
    "\n",
    "for line in open('xtest_obfuscated.txt'):\n",
    "    x_test += [line.strip()]\n",
    "    \n",
    "# convert characters to indices using all_chars dictionary\n",
    "for i, line in enumerate(x_test):\n",
    "    x_test[i] = [all_chars[char] for char in line]\n",
    "    \n",
    "# pad shorter lines to max_len\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=max_len)\n",
    "\n",
    "# write results to file\n",
    "y_test = model.predict(x_test)\n",
    "y_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "with open('ytest.txt', 'w') as ytest:\n",
    "    for label in y_test:\n",
    "        ytest.write(str(label) + '\\n')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  },
  "toc": {
   "nav_menu": {
    "height": "98px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
